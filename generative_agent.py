# -*- coding: utf-8 -*-
"""generative agent

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X_GptERcek-oxk24befJylxpt7Rzdh3h
"""

#!pip install termcolor > /dev/null

from google.colab import drive

drive.mount('/content/gdrive')

import logging

logging.basicConfig(level=logging.ERROR)

!pip install -U langchain-community
!pip install langchain_openai
!pip install langchain_experimental
!pip install faiss-cpu
!pip install pydantic==2.9.2

# !pip install gpt4all

from datetime import datetime, timedelta
from typing import List
import openai
from langchain.docstore import InMemoryDocstore
from langchain.retrievers import TimeWeightedVectorStoreRetriever
from langchain_community.vectorstores import FAISS
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from termcolor import colored
from langchain_experimental.generative_agents import (
    GenerativeAgent,
    GenerativeAgentMemory,
)
import faiss
from langchain_community.llms import GPT4All

USER_NAME = "Person A"  # The name you want to use when interviewing the agent.
import os

os.environ["OPENAI_API_KEY"] =
LLM=ChatOpenAI(
    model="gpt-3.5-turbo",
    temperature=0,
    max_tokens=None,
    timeout=None,
    max_retries=2,
    api_key=  # if you prefer to pass api key in directly instaed of using env vars

)

import math


def relevance_score_fn(score: float) -> float:
    """Return a similarity score on a scale [0, 1]."""
    # This will differ depending on a few things:
    # - the distance / similarity metric used by the VectorStore
    # - the scale of your embeddings (OpenAI's are unit norm. Many others are not!)
    # This function converts the euclidean norm of normalized embeddings
    # (0 is most similar, sqrt(2) most dissimilar)
    # to a similarity function (0 to 1)
    return 1.0 - score / math.sqrt(2)


def create_new_memory_retriever():
    """Create a new vector store retriever unique to the agent."""
    # Define your embedding model
    embeddings_model = OpenAIEmbeddings()
    # Initialize the vectorstore as empty
    embedding_size = 1536
    index = faiss.IndexFlatL2(embedding_size)
    vectorstore = FAISS(
        embeddings_model.embed_query,
        index,
        InMemoryDocstore({}),
        {},
        relevance_score_fn=relevance_score_fn,
    )
    return TimeWeightedVectorStoreRetriever(
        vectorstore=vectorstore, other_score_keys=["importance"], k=15
    )

"""# Initializing a Avatar"""

tommies_memory = GenerativeAgentMemory(
    llm=LLM,
    memory_retriever=create_new_memory_retriever(),
    verbose=False,
    reflection_threshold=8,  # we will give this a relatively low number to show how reflection works
)

tommie = GenerativeAgent(
    name="Tommie",
    age=25,
    traits="anxious, likes design, talkative",  # You can add more persistent traits here
    status="looking for movie to watch and he is free at home in a sunny morning of the weekend in the United States",  # When connected to a virtual world, we can have the characters update their status
    memory_retriever=create_new_memory_retriever(),
    llm=LLM,
    memory=tommies_memory,
)

tommie.status

print(tommie.get_summary())

"""# Create the Recommender Agent"""

rs_memory = GenerativeAgentMemory(
    llm=LLM,
    memory_retriever=create_new_memory_retriever(),
    verbose=False,
    reflection_threshold=8,  # we will give this a relatively low number to show how reflection works
)

rs = GenerativeAgent(
    name="Recommender",
    age=20,
    traits="calm, knowledgable",  # You can add more persistent traits here
    status="Giving personalized movies based on daily observation and explain why it fits the clients",  # When connected to a virtual world, we can have the characters update their status
    memory_retriever=create_new_memory_retriever(),
    llm=LLM,
    daily_summaries=[
        (
            "Recommender needs to use only these movies to make recommendation to client based on the movie characteristics and user personalities."
        )
    ],
    memory=rs_memory,
)

tommie.traits

observations=["Recommender open the dataset and he saw a historical record of users' preference over different movies based on rating. User A who is funny, talk a lot, gives the rating of 5 on the movie Inception (2010). User B who is young, calm, quiet, gives the rating of 5 on the movie The Grand Budapest Hotel (2014). User C who is indifferent, nonchalant, gives the rating of 5 on the movie Parasite (2019). User D who is sporty, easy going, gives the rating of 5 on the movie The Matrix (1999).,"]

for observation in observations:
    rs.memory.add_memory(observation)

rs.get_summary(force_refresh=True)

"""# Conversation without MF"""

def run_conversation(agents: List[GenerativeAgent], initial_observation: str) -> None:
    """Runs a conversation between agents."""
    _, observation = agents[1].generate_reaction(initial_observation)
    print(observation)
    turns = 0
    while True:
        break_dialogue = False
        for agent in agents:
            stay_in_dialogue, observation = agent.generate_dialogue_response(
                observation
            )
            print(observation)
            # observation = f"{agent.name} said {reaction}"
            if not stay_in_dialogue:
                break_dialogue = True
        if break_dialogue:
            break
        turns += 1

agents = [tommie, rs]
run_conversation(
    agents,
    "Tommie said: Hi, Recommender. Based on my traits as a anxious, likes design, talkative person, can you suggest me what movie should I watch?",
)

agents = [tommie, rs]
run_conversation(
    agents,
    "Tommie said: Hi, Recommender. Out of all movies you observed today and based on my traits as a anxious, likes design, talkative person, can you suggest me what movie should I watch?",
)

def interview_agent(agent: GenerativeAgent, message: str) -> str:
    """Help the notebook user interact with the agent."""
    new_message = f"{USER_NAME} says {message}"
    return agent.generate_dialogue_response(new_message)[1]

interview_agent(rs, "What is the trait of tommie?")

"""# Conversation with algorithm"""

rs_withalgo_memory = GenerativeAgentMemory(
    llm=LLM,
    memory_retriever=create_new_memory_retriever(),
    verbose=False,
    reflection_threshold=8,  # we will give this a relatively low number to show how reflection works
)

rs_withalgo = GenerativeAgent(
    name="Algo",
    age=20,
    traits="calm, knowledgable",  # You can add more persistent traits here
    status="Giving personalized movies based on daily observation and explain why it fits the clients",  # When connected to a virtual world, we can have the characters update their status
    memory_retriever=create_new_memory_retriever(),
    llm=LLM,
    daily_summaries=[
        (
            "Recommender needs to use only these movies to make recommendation to client based on the movie characteristics and user personalities."
        )
    ],
    memory=rs_memory,
)

"""# Conversation with Factorization:

## Clustering and data import
"""

import pandas as pd
frappe_path = "/content/gdrive/MyDrive/Context-aware Dataset/frappe.csv"
# Reload the data with tab ('\t') as the delimiter to handle the issue
data = pd.read_csv(frappe_path , sep='\t')
from sklearn.preprocessing import OneHotEncoder
from sklearn.cluster import KMeans
import numpy as np

# Select features for clustering
features = data[['daytime', 'isweekend', 'homework', 'cost', 'weather', 'country']]

# One-hot encode the categorical variables
encoder = OneHotEncoder()
encoded_features = encoder.fit_transform(features)

# Perform clustering using KMeans (number of clusters can be tuned later)
n_clusters = 5  # Initial assumption, can be optimized
kmeans = KMeans(n_clusters=n_clusters, random_state=42)
clusters = kmeans.fit_predict(encoded_features)

# Add the cluster assignments to the original data
data['cluster'] = clusters

# Create a rating matrix with clusters as rows, items as columns, and values as the sum of 'cnt'
rating_matrix = data.pivot_table(
    index='cluster', columns='item', values='cnt', aggfunc='mean', fill_value=0
)

# Display the resulting rating matrix
# import ace_tools as tools; tools.display_dataframe_to_user(name="Cluster-Item Rating Matrix", dataframe=rating_matrix)

import re

def parse_text_to_features(input_text):
    """
    Parse the input text to extract structured features.

    Args:
        input_text (str): Unstructured text describing the person's situation.

    Returns:
        list: A list of structured features [daytime, isweekend, homework, cost, weather, country].
    """
    # Define patterns for extracting each feature
    daytime_pattern = r"(morning|afternoon|evening|sunset|night)"
    isweekend_pattern = r"(weekend|weekday)"
    homework_pattern = r"(home|work)"
    cost_pattern = r"(free|paid)"
    weather_pattern = r"(sunny|cloudy|rainy|stormy|unknown)"
    country_pattern = r"in the ([A-Za-z\s]+)"

    # Extract features using regex
    daytime = re.search(daytime_pattern, input_text)
    isweekend = re.search(isweekend_pattern, input_text)
    homework = re.search(homework_pattern, input_text)
    cost = re.search(cost_pattern, input_text)
    weather = re.search(weather_pattern, input_text)
    country = re.search(country_pattern, input_text)

    # Get matched groups or default to 'unknown'
    daytime = daytime.group(0) if daytime else 'unknown'
    isweekend = 'weekend' if 'weekend' in input_text else 'weekday'
    homework = homework.group(0) if homework else 'unknown'
    cost = cost.group(0) if cost else 'unknown'
    weather = weather.group(0) if weather else 'unknown'
    country = country.group(1) if country else 'unknown'

    return [daytime, isweekend, homework, cost, weather, country]

# Example text input
input_text = "looking for movie to watch and he is free at home in a sunny morning of the weekend in the United States"

# Parse the text to structured features
new_person_features = parse_text_to_features(input_text)

def classify_person(new_person_features, kmeans_model, encoder):
    """
    Classify a new person into an existing cluster.

    Args:
        new_person_features (list): A list of features for the person
                                    [daytime, isweekend, homework, cost, weather, country].
        kmeans_model (KMeans): Trained KMeans model.
        encoder (OneHotEncoder): Fitted OneHotEncoder.

    Returns:
        int: Cluster number the person belongs to.
    """
    # Ensure the input is reshaped properly for encoding
    new_person_array = [new_person_features]

    # Transform the input features using the same encoder
    encoded_person = encoder.transform(new_person_array).toarray()

    # Predict the cluster for the new person
    cluster = kmeans_model.predict(encoded_person)[0]

    return cluster

# Example usage:
# new_person = ['morning', 'weekend', 'home', 'free', 'sunny', 'United States']  # Replace with your values
person_cluster = classify_person(new_person_features, kmeans, encoder)

person_cluster

rating_matrix

"""## Factorization Module"""

import numpy as np
from sklearn.decomposition import NMF

def run_matrix_factorization(data_matrix: np.ndarray, n_components: int = 5):
    """
    Perform matrix factorization and reconstruct the finished rating matrix.

    Args:
        data_matrix (np.ndarray): The input matrix to factorize.
        n_components (int): Number of latent factors.

    Returns:
        np.ndarray: The reconstructed rating matrix.
    """
    # Perform matrix factorization using NMF
    model = NMF(n_components=n_components, init="random", random_state=42)
    W = model.fit_transform(data_matrix)
    H = model.components_

    # Reconstruct the finished rating matrix
    reconstructed_matrix = np.dot(W, H)

    return reconstructed_matrix
from datetime import datetime

class MemoryWithFactorization:
    def __init__(self, memory: GenerativeAgentMemory):
        """
        Wrapper for incorporating matrix factorization with GenerativeAgentMemory.

        Args:
            memory (GenerativeAgentMemory): An instance of the GenerativeAgentMemory class.
        """
        self.memory = memory

    def add_factorization_results(self, data_matrix: np.ndarray, n_components: int = 5):
        """
        Run matrix factorization and add results to the memory.

        Args:
            data_matrix (np.ndarray): Input data for matrix factorization.
            n_components (int): Number of latent factors.
        """
        # Run matrix factorization
        topics = run_matrix_factorization(data_matrix, n_components=n_components)

        # Add each topic to memory
        now = datetime.now()
        for topic in topics:
            self.memory.add_memory(f"Matrix Factorization Result: {topic}", now=now)

        if self.memory.verbose:
            logger.info(f"Added {len(topics)} factorization results to memory.")

def recommend_top_items(cluster_id, rating_matrix, top_n=10):
    """
    Recommend the top N items for a given cluster based on cnt values.

    Args:
        cluster_id (int): The cluster ID of the user.
        rating_matrix (DataFrame): The cluster-item rating matrix.
        top_n (int): Number of top items to recommend.

    Returns:
        List[Tuple[int, float]]: A list of top N items and their cnt values.
    """
    # Extract the row for the given cluster
    cluster_ratings = rating_matrix.loc[cluster_id]

    # Sort items by cnt in descending order and get the top N items
    top_items = cluster_ratings.sort_values(ascending=False).head(top_n)

    # Return items as a list of tuples (item_id, cnt)
    return list(top_items.items())
finished_matrix = run_matrix_factorization(rating_matrix.values, n_components=3)
finished_rating_df = pd.DataFrame(
    finished_matrix, index=rating_matrix.index, columns=rating_matrix.columns
)

# Recommend top 10 items for a user in cluster 1
top_items_for_cluster_1 = recommend_top_items(cluster_id=person_cluster, rating_matrix=finished_rating_df, top_n=4)
item_ids = [item[0] for item in top_items_for_cluster_1 ]
# Display the recommendations

# Assume `memory` is an initialized instance of GenerativeAgentMemory
memory_wrapper = MemoryWithFactorization(rs_memory)

# Example data matrix (replace with actual data)
data_matrix = np.random.rand(10, 10)  # Replace with your own data matrix
n_components = 3
prompt = f"""
You are an application recommender agent. Based on the user's traits: {tommie.traits},
and the following apps retrieved from the dataset:
{item_ids}

Recommend an app and explain why they suit the user's preferences.
"""
# Add factorization results to memory
memory_wrapper.add_factorization_results(data_matrix, n_components=n_components)

rs.add_memory(prompt)

def generate_grounded_recommendation(agent, user_traits, retrieved_movies):
    prompt = f"""
    You are a movie recommender agent. Based on the user's traits: {user_traits},
    and the following movies retrieved from the dataset:
    {retrieved_movies}

    Recommend 3 movies and explain why they suit the user's preferences.
    """
    return agent.llm(prompt)

def validate_response(response, valid_data):
    """Check if the response is grounded in valid data."""
    if any(item in response for item in valid_data):
        return True
    return False
def run_conversation(agents: List[GenerativeAgent], initial_observation: str, valid_data: List[str]) -> None:
    """Runs a conversation between agents with response validation."""
    _, observation = agents[1].generate_reaction(initial_observation)
    print(observation)
    turns = 0
    while True:
        break_dialogue = False
        for agent in agents:
            # Validate the observation before generating a response
            if not validate_response(observation, valid_data):
                print("Detected hallucination. Ending dialogue.")
                return
            stay_in_dialogue, observation = agent.generate_dialogue_response(
                observation
            )
            print(observation)
            if not stay_in_dialogue:
                break_dialogue = True
        if break_dialogue:
            break
        turns += 1
def run_conversation_with_retrieval(agents: List[GenerativeAgent], initial_observation: str, retriever) -> None:
    """Runs a conversation between agents with retrieval grounding."""
    _, observation = agents[1].generate_reaction(initial_observation)
    print(observation)
    turns = 0
    while True:
        break_dialogue = False
        for agent in agents:
            # Retrieve relevant data for grounding
            retrieved_data = retriever.retrieve(observation)
            # Validate observation against retrieved data
            if not validate_response(observation, retrieved_data):
                print("Response not grounded. Ending dialogue.")
                return
            stay_in_dialogue, observation = agent.generate_dialogue_response(
                observation
            )
            print(observation)
            if not stay_in_dialogue:
                break_dialogue = True
        if break_dialogue:
            break
        turns += 1
def run_conversation_with_feedback(agents: List[GenerativeAgent], initial_observation: str, valid_data: List[str]) -> None:
    """Runs a conversation with self-correction for hallucination."""
    _, observation = agents[1].generate_reaction(initial_observation)
    print(observation)
    turns = 0
    while True:
        break_dialogue = False
        for agent in agents:
            if not validate_response(observation, valid_data):
                correction_prompt = f"""
                Your last response was not valid. Please revise it to align with the dataset:
                {valid_data}.
                """
                observation = agent.llm(correction_prompt)
                print(f"Corrected Observation: {observation}")
            stay_in_dialogue, observation = agent.generate_dialogue_response(
                observation
            )
            print(observation)
            if not stay_in_dialogue:
                break_dialogue = True
        if break_dialogue:
            break
        turns += 1

agents = [tommie, rs]
initial_observation = "Tommie said: Hi, Recommender. Based on my traits, can you suggest me a movie?"
run_conversation_with_retrieval(agents, initial_observation, valid_movies)

"""# Evaluation Experiment

## Abalation study 1: How many hallucinated answers for each result? - Use stacked barchart - For ratings of random 4 people who rated more than 20 ratings, provide how many hallucinated, wrong and right answers -> To validate with hallucination approaches are the best
"""

import matplotlib.pyplot as plt

# Data
categories = ["Before Factorization", "After Factorization", "After Factorization with Feedback"]

# Plotting
fig, ax = plt.subplots(figsize=(8, 6))

# Stacked bar chart
bar_width = 0.5
ax.bar(categories, hallucination, label="Hallucination", color="red", edgecolor="black")
ax.bar(categories, wrong, bottom=hallucination, label="Wrong", color="orange", edgecolor="black")
ax.bar(categories, right, bottom=[h + w for h, w in zip(hallucination, wrong)], label="Right", color="green", edgecolor="black")

# Adding labels and title
ax.set_title("Stacked Bar Chart of Factorization Stages", fontsize=14)
ax.set_ylabel("Percentage", fontsize=12)
ax.legend(title="Components")

# Show grid and chart
ax.grid(axis="y", linestyle="--", alpha=0.7)
plt.tight_layout()
plt.show()

"""## Ablation Study 2: Role of Factorization"""

# Data for pie charts
labels = ["Hallucination", "Wrong", "Right"]

# Creating pie charts
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

# Before factorization
axes[0].pie(data_before, labels=labels, autopct='%1.1f%%', startangle=90, colors=["red", "orange", "green"])
axes[0].set_title("Before Factorization")

# After factorization without clustering
axes[1].pie(data_after_no_clustering, labels=labels, autopct='%1.1f%%', startangle=90, colors=["red", "orange", "green"])
axes[1].set_title("After Factorization (No Clustering)")

# After factorization with clustering
axes[2].pie(data_after_clustering, labels=labels, autopct='%1.1f%%', startangle=90, colors=["red", "orange", "green"])
axes[2].set_title("After Factorization (With Clustering)")

# Adjust layout and display
plt.tight_layout()
plt.show()

# Add a pie for instruction tuning

"""## Benchmarking with other: 1 GPT, 3 Matrix Factorization and 1 normal DeepLearning model"""

results_df

